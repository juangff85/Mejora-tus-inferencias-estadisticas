---
title: "Sesgo de confirmación y escepticismo organizado"
---

# Sesgo de confirmación y escepticismo organizado

16. Sesgo de Confirmación y Escepticismo Organizado

No puedo dar a ningún científico, de cualquier edad, un mejor consejo que este: la intensidad de la convicción de que una hipótesis es verdadera no tiene relación con si realmente lo es. La importancia de la fuerza de nuestra convicción es únicamente proporcionar un incentivo proporcionalmente fuerte para averiguar si la hipótesis resistirá una evaluación crítica.
— Medawar, 1979, Advice to a Young Scientist
Ser científico es una carrera gratificante pero desafiante. Hacer ciencia puede conducir a la satisfacción intelectual de hacer descubrimientos o aumentar nuestra comprensión sobre cuestiones importantes, a la sensación gratificante de contribuir a soluciones para problemas relevantes que enfrenta la sociedad, a interactuar con colegas estimulantes, al reconocimiento de pares y del público en general, así como a la posibilidad de obtener un ingreso decente si te conviertes en un experto internacionalmente solicitado en tu campo. Al mismo tiempo, puede ser una carrera difícil que requiere mucho trabajo, incertidumbre sobre tu futuro profesional, momentos en los que se logra poco avance en el conocimiento, competitividad o incluso animosidad hacia otros científicos, y una sensación constante de presión por alcanzar metas (National Academy of Sciences et al., 2009).
Aunque la ciencia es un esfuerzo colectivo, los científicos a menudo tienen un fuerte compromiso personal con su trabajo. Están motivados para tener éxito, y se sienten decepcionados si su trabajo no lo logra. En su libro “La ciencia moderna y la naturaleza de la vida”, William Beck (1957) escribe:
Cada paso sucesivo en el método científico exige una mayor inversión emocional y añade dificultad a mantenerse objetivo. Cuando el ego está implicado, la autocrítica puede ser difícil (¿quién ha oído hablar de dos científicos compitiendo para demostrar que el otro tiene razón?). Siempre se tiene un interés personal en que el resultado sea exitoso y, nos guste admitirlo o no, cada uno de nosotros siente la presión de tener éxito, de abrir 'nuevos caminos' quizás antes de haber dominado los anteriores.
Es evidente, por tanto, cómo las tendencias neuróticas latentes pueden influir y distorsionar los mandatos puros del método científico, y generar error, valores poco realistas, ansiedad y —seamos sinceros, dado que la ciencia se realiza a puerta cerrada— deshonestidad. Como los científicos son humanos y la ciencia no lo es, como en todos los campos, el fino hilo de la integridad a veces se tensa hasta el punto de romperse.
El reconocimiento de que la ciencia es una actividad humana no ha pasado desapercibido. En 1620, Francis Bacon escribió el libro Novum Organum (o Nuevo Método), que proporcionó una primera descripción de un método científico moderno, centrado en el empirismo y el razonamiento inductivo. Bacon ya comprendía, hace más de 400 años, que las personas no son observadoras pasivas, y ofrece una descripción muy temprana de lo que hoy llamaríamos sesgo de confirmación:
El entendimiento humano, una vez que se ha planteado una proposición (ya sea por aceptación general y creencia, o por el placer que proporciona), fuerza todo lo demás a añadir apoyo y confirmación; y aunque puedan existir ejemplos abundantes y convincentes en sentido contrario, no los observa o los desprecia, o los descarta con alguna distinción, con prejuicio violento e injusto, antes que sacrificar la autoridad de sus primeras conclusiones.
Bien respondió quien, al ser mostrado en un templo las tablillas votivas colgadas por quienes escaparon del naufragio, preguntó si entonces se debía reconocer el poder de los dioses, inquiriendo: “¿Y dónde están los retratos de quienes perecieron a pesar de sus votos?”. Toda superstición es bastante similar, ya se trate de astrología, sueños, presagios, juicios retributivos o cosas parecidas, en todas las cuales los creyentes engañados observan los eventos que se cumplen, pero descuidan y omiten los fallos, aunque sean mucho más comunes. Pero este mal se insinúa aún más astutamente en la filosofía y las ciencias, en las cuales una máxima establecida vicia y gobierna todas las demás circunstancias, aunque estas últimas sean mucho más dignas de confianza.
Además, incluso sin esa prisa y falta de reflexión (que ya hemos mencionado), es el error peculiar y perpetuo del entendimiento humano el sentirse más movido y excitado por afirmaciones que por negaciones, cuando en realidad debería ser imparcial. De hecho, para establecer un verdadero axioma, la instancia negativa es la más poderosa. En un artículo clásico sobre el sesgo de confirmación, Nickerson (1998) lo define como:
La búsqueda o interpretación de evidencia de maneras que favorecen las creencias existentes, expectativas o una hipótesis mantenida.
Los factores humanos que influyen (o sesgan) la generación del conocimiento científico han recibido relativamente poca atención por parte de los filósofos de la ciencia, aunque sería ingenuo creer que los científicos persiguen objetivamente la verdad. Como escribe el filósofo de la ciencia Chang (2022):
Existe una tendencia en la filosofía de la ciencia a presentar al científico como un ser fantasmal que simplemente tiene grados de creencia en varias afirmaciones descriptivas, las cuales se ajustan según ciertas reglas del pensamiento racional (por ejemplo, el teorema de Bayes), eliminando así cualquier necesidad de juicio real. Todo lo que no encaja en esta visión extraña y empobrecida, tendemos a denigrarlo como asuntos de ‘mera’ psicología o sociología.
El sociólogo de la ciencia Robert Merton (1942) creía que cuatro conjuntos de imperativos institucionales —universalismo, comunismo, desinterés y escepticismo organizado— conforman el ethos de la ciencia moderna.
Universalismo significa que “la aceptación o el rechazo de afirmaciones que entran en el ámbito de la ciencia no debe depender de las características personales o sociales de quien las propone”.
Comunismo significa que “los hallazgos sustantivos de la ciencia son producto de la colaboración social y se asignan a la comunidad”. Los científicos no son dueños de sus teorías; en el mejor de los casos, reciben reconocimiento por desarrollarlas. Como escribe Merton: “El secreto es la antítesis de esta norma; la comunicación plena y abierta es su aplicación”.
Desinterés no ocurre a nivel individual —un científico puede tener pasiones y motivaciones— sino a nivel institucional. La institución de la ciencia tiene como norma el desinterés, lo que significa que las afirmaciones deben ser veraces y no engañosas. Según Merton, los científicos están sometidos a una vigilancia rigurosa: son responsables ante sus pares, quienes revisarán su trabajo, y por lo tanto, solo el desinterés conducirá a afirmaciones que sobrevivan al escrutinio.
Escepticismo organizado significa el “escrutinio de las creencias en términos de criterios empíricos y lógicos”. Las afirmaciones solo se aceptan después de haber sobrevivido al examen por parte de colegas.
Como ocurre con cualquier norma, no todos los individuos la suscriben completamente y, más importante aún, no todos se comportan de acuerdo con ellas (al menos no todo el tiempo). Por ejemplo, una norma común es decir la verdad cuando se habla con otras personas. Sin embargo, incluso si defendemos esta norma, puede que no siempre digamos la verdad nosotros mismos. Y podríamos creer que otras personas mienten con más frecuencia que nosotros. Este es exactamente el patrón que Anderson y colegas (2007) encontraron en una encuesta realizada a científicos de EE. UU (Ver figura 1)
 
Figura 1: Promedios de adhesión normativa y contranormativa, y comportamiento según Anderson et al. (2007).
Los científicos suscriben las normas mertonianas (la puntuación máxima posible es 12). También admiten que no siempre siguen estas normas en su propio comportamiento, y creen que otras personas aún las siguen menos. El patrón es opuesto en el caso de las contranormas (por ejemplo, el secretismo, el interés personal, etc.). Cuando se les pregunta, los científicos no consideran que los miembros de su propia profesión sean completamente objetivos. En una interesante serie de entrevistas a científicos involucrados en el alunizaje del Apolo, Mitroff (1974) concluyó:
Cada uno de los científicos entrevistados en la primera ronda de entrevistas indicó que pensaba que la noción del científico objetivo y emocionalmente desinteresado era ingenua.
Su artículo está lleno de citas excelentes que ilustran esta conclusión, como por ejemplo:
Científico B: El científico no implicado y sin emociones es tan ficticio como el científico loco que destruirá el mundo por conocimiento. La mayoría de los científicos que conozco tienen teorías y están buscando datos que las respalden; no están examinando los datos de forma impersonal en busca de una teoría que se ajuste a ellos. Hay que hacer una clara distinción entre no ser objetivo y hacer trampa. Un buen científico no se negará a cambiar su teoría si encuentra una gran cantidad de evidencia que no la apoya, pero en esencia, está intentando defenderla. Sin compromiso [emocional], uno no tendría la energía ni el impulso para seguir adelante, a veces contra obstáculos extremadamente difíciles. No falsificas conscientemente la evidencia en ciencia, pero le das menos importancia a un dato que te contradice. Ningún científico respetable hace esto conscientemente, pero sí lo haces de forma subconsciente.
Científico G: Cada idea científica necesita un representante personal que la defienda y la nutra, para que no sufra una muerte prematura.
Estas entrevistas revelan que los científicos creen que el compromiso con una idea o teoría específica es necesario si se quiere tener la motivación para seguir explorándola, incluso cuando las circunstancias son difíciles, o para asegurar que una idea no sea descartada demasiado fácilmente. En otras palabras, el sesgo de confirmación incluso podría tener un papel positivo que desempeñar.
Aunque hoy en día existen filósofos de la ciencia que reconocen que la ciencia es un proceso social (Douglas, 2009; Longino, 1990), la mayoría de quienes estudian los factores humanos en la investigación científica provienen de campos como la psicología de la ciencia. Estos factores también son investigados desde disciplinas como la sociología de la ciencia, los estudios de ciencia y tecnología, o la metaciencia. Investigadoras e investigadores en estos campos intentan describir las formas en que quienes investigan caen víctimas del sesgo de confirmación, analizan los mecanismos subyacentes que lo provocan y proponen intervenciones para reducir su impacto en la ciencia.
Por ejemplo, Mahoney (1979) revisó la literatura relacionada con la descripción típica que aparece en los libros de texto sobre los científicos como personas objetivas, racionales, de mente abierta, inteligentes, íntegras, y dispuestas a compartir su conocimiento de manera abierta y cooperativa, y concluyó:
1.	El científico no es inmune a los sesgos perceptivos y con frecuencia reacciona con bastante emotividad ante cuestiones técnicas y epistemológicas.
2.	Aún está por demostrarse que los científicos sean más lógicos que quienes no lo son en la realización e interpretación de su trabajo.
3.	El científico puede, a veces, mostrarse poco receptivo a datos relevantes y —particularmente en el caso de quienes desarrollan teorías— propenso a especulaciones apresuradas y a una tenacidad dogmática.
4.	Aunque los científicos suelen tener un CI más alto que la población general, aún debe demostrarse que pequeñas diferencias intelectuales tengan un impacto sustancial en la competencia profesional o en la contribución al conocimiento.
5.	Informes sobre fabricación de datos y sesgo del experimentador sugieren que tales fenómenos no son ni raros ni triviales.
6.	Los científicos tienden a ser reservados y desconfiados hasta que logran establecer públicamente la prioridad de sus hallazgos; las disputas por el crédito personal y la autoría suelen dar lugar a discusiones amargas.
Entonces, ¿por qué la ciencia parece seguir funcionando, a pesar de todas estas limitaciones tan humanas que muestran quienes la hacen? Una manera de entenderlo es considerar la ciencia como un método que usan los grupos de personas para hacer afirmaciones, aplicando procedimientos destinados a reducir el rol del sesgo de confirmación. Aunque la ciencia abarca mucho más que un conjunto de reglas para evitar este sesgo, muchas prácticas —como la revisión por pares, la realización de estudios de replicación independientes o la especificación del nivel alfa antes de observar los datos— solo se entienden desde esta perspectiva. Algunas y algunos científicos consideran los esfuerzos activos por resistir el sesgo de confirmación como una característica esencial de una buena práctica científica. Como dijo Feynman:
El primer principio es que no debes engañarte a ti mismo —y tú eres la persona más fácil de engañar. — Feynman (1974)
16.1 Sesgo de confirmación en la Ciencia

Wason (1960) creó una tarea sencilla para examinar cómo las personas ponen a prueba hipótesis. Primero recibes una serie de tres números. Tu tarea es desarrollar una hipótesis sobre la regla subyacente que ha generado esos tres números. Luego puedes probar tu hipótesis sugiriendo un nuevo conjunto de tres números, y te dirán si ese conjunto sigue la regla que debes descubrir: sí o no. Te doy los siguientes tres números: 2, 4, 8.
Puedes pensar en una regla que haya generado esa serie. Para probar tu hipótesis, puedes proponer un nuevo conjunto de tres números. Tómate un momento para pensar qué números sugerirías, y luego recibirás la respuesta de si siguen o no la regla. Digamos que decides proponer los números 3, 6, 12 o 5, 10, 20. Estos números siguen la regla “el primer número se duplica, y luego se vuelve a duplicar”. Si hubieras propuesto esos números, te habrían dicho que efectivamente siguen la regla que debías descubrir. Sin embargo, si hubieras propuesto los números 2, 3, 9, también habrías recibido la respuesta de que este conjunto sigue la regla subyacente. La regla real que había que descubrir era: “tres números en orden creciente de magnitud”.
Como la mayoría de personas que realizan esta tarea, probablemente probaste un conjunto de tres números que confirmaban la regla que tenías en mente. Que la regla sea confirmada te dice que puede ser correcta, pero no descarta que muchas otras reglas también lo sean. En cambio, si pruebas un conjunto de números que crees que no seguirán la regla, como por ejemplo 1, 2, 3, y descubres que sí la siguen, eso te indica con certeza que tu regla original era incorrecta. Confirmar y refutar predicciones es igualmente importante, pero en general las personas tienden menos a intentar demostrarse que están equivocadas. Este conocimiento sobre la psicología humana es útil, porque nos permite desarrollar métodos y procedimientos que contrarresten los efectos negativos de nuestra inclinación a querer confirmar nuestras hipótesis.
En su artículo titulado “Ciencia Patológica”, Langmuir (1989) discute dos ejemplos de sesgo de confirmación en física: El primero es el efecto Davis-Barnes, que describía un comportamiento inesperado de partículas alfa al interactuar con electrones en un campo magnético. El segundo caso es el de los rayos N, una forma de radiación hipotética inspirada en el descubrimiento de los rayos X, descrita por el físico francés Blondlot en 1903 y confirmada inicialmente por otros físicos. En ambos casos, el escepticismo respecto a los resultados iniciales llevó a que otros científicos realizaran inspecciones presenciales de los experimentos. Concluyeron que los resultados se debían a errores del observador. Como escribe Langmuir: “Estos son casos donde no hay deshonestidad, pero donde las personas se dejan engañar por una falta de comprensión sobre lo que los seres humanos pueden hacerse a sí mismos: ser conducidos al error por efectos subjetivos, pensamiento ilusorio o interacciones en el umbral perceptual.”
A veces, las y los científicos cometen fraude científico deliberado y fabrican datos. Pero no siempre está claro dónde trazar la línea entre el sesgo intencional y el no intencional. Por ejemplo, en un caso famoso, el del genetista Gregor Mendel, quien estudió la herencia en plantas de guisante. Reanálisis posteriores de sus datos por el estadístico y genetista Ronald Fisher revelaron que sus resultados eran sospechosamente cercanos a los resultados esperados (Fisher, 1936). Aunque se coincide en que los resultados son estadísticamente inverosímiles, es difícil identificar la causa exacta.
La improbabilidad estadística podría deberse a errores al reportar detalles del experimento, errores de clasificación, o incluso a que un asistente sintiera cierta presión por informar resultados acordes con lo esperado (Radick, 2022). Una de las razones para adoptar prácticas de ciencia abierta es que la comunidad científica se beneficiaría de una mayor transparencia sobre lo que ocurrió en situaciones donde surgen dudas sobre la validez de los resultados. No solo las y los científicos fabrican datos: el alumnado también lo hace.
En un artículo increíblemente interesante que documenta intentos de replicar un estudio como tarea de clase, Azrin y colegas (1961) encontraron que muchas y muchos estudiantes fabricaron total o parcialmente los datos porque seguir el procedimiento experimental era demasiado difícil. En un experimento de clase, solo una persona informó tener problemas para llevar a cabo el experimento tal como se indicaba. Sin embargo, cuando se discutió el experimento más tarde y esa persona honesta admitió haber intentado realizarlo seis veces sin éxito antes de rendirse, ¡otras ocho personas también admitieron haber tenido problemas y haberse desviado considerablemente de las instrucciones!
Peor aún, en otra réplica del mismo estudio como tarea de clase, cuando una persona preguntó: “Estoy teniendo problemas con mi experimento, ¿puedes decirme cómo hiciste el tuyo?”, 12 de 19 estudiantes admitieron inmediatamente haber fabricado datos. Podemos imaginar muchas razones por las que el alumnado fabricaría datos: no querer admitir que fallaron en seguir las instrucciones y sentirse mal, o simplemente para evitar hacer el trabajo real.
En una clase que co-impartí con una colega hace años, también ocurrió algo similar. Pedimos a las y los estudiantes que recopilaran datos mediante una breve encuesta a 10 personas conocidas, para que tuvieran datos reales que analizar durante el curso. En ese momento no nos dimos cuenta de que la encuesta (que también diseñaban como parte del curso) terminaría siendo más larga de lo previsto, ni de que muchas personas encontraron incómodo pedirle ese favor a otras. Nadie nos dijo que tenía dificultades para seguir las instrucciones. En cambio, muchas fabricaron encuestas hasta completar las 10 necesarias. Como docentes, evidentemente habíamos pedido algo poco realista. Pero si alguien nos hubiese comunicado honestamente la dificultad, habríamos modificado la tarea (como hicimos al año siguiente). El código de conducta para la integridad en la investigación se aplica tanto al profesorado como al alumnado. Siempre que sientas presión y te veas tentado a violar este código (por ejemplo, fabricando datos), ¡no lo hagas! En su lugar, informa del problema a una o un docente, o a una persona asesora confidencial si te resulta más cómodo.
Como se discutió en la sección sobre prácticas de investigación cuestionables, a veces las personas investigadoras usan de manera oportunista la flexibilidad de los métodos para aumentar la probabilidad de encontrar apoyo a sus hipótesis. A menudo no está claro en qué medida son conscientes de lo problemático de este comportamiento, y por eso es difícil determinar cuándo es un acto deshonesto y cuándo es simplemente el resultado de no entender bien lo que hacen.
Estas prácticas se conocen desde hace tiempo. Kish (1959) ya había mencionado uno de los usos incorrectos de las pruebas estadísticas: “Primero, está el 'disparo con escopeta' en busca de diferencias significativas. [...] El investigador de vista aguda que examine los resultados de mil lanzamientos aleatorios de monedas perfectas podría descubrir y presentar alrededor de cincuenta resultados 'significativos' (al nivel de p = .05). Tal vez el problema se ha agudizado ahora que las computadoras de alta velocidad permiten realizar cientos de pruebas de significancia”.
Barber (1976) nos recuerda: “Dado que los experimentos son diseñados y llevados a cabo por personas falibles, tienen tantos obstáculos como cualquier otra empresa humana”. Y ofrece un panorama extenso sobre las formas en que los investigadores pueden sesgar sus conclusiones. Enumera muchas maneras en que se pueden sesgar los resultados, ya sea como experimentador (por ejemplo, tratando de forma ligeramente distinta a quienes están en la condición experimental y a quienes están en el grupo de control), o como analista (por ejemplo, probando muchas formas de analizar los datos hasta encontrar un resultado significativo). Estas preocupaciones solo recibieron una atención amplia en psicología al comienzo de la crisis de replicación, por ejemplo, a través del artículo “False-Positive Psychology: Undisclosed Flexibility in Data Collection and Analysis Allows Presenting Anything as Significant” (Simmons et al., 2011).
Un mecanismo final mediante el cual opera el sesgo de confirmación es el conocido como sesgo de citación, donde las autoras y autores seleccionan investigaciones que respaldan sus afirmaciones, mientras ignoran evidencia que las contradice. Las citas son una práctica fundamental en la ciencia. Se utilizan en la introducción de los artículos para presentar el estado del conocimiento y justificar la investigación.
También sirven para dar crédito a quienes realizaron trabajos previos útiles, y el número de citas que recibe un artículo suele usarse (al menos en parte) como medida para evaluar la calidad del trabajo científico realizado. Por ello, es importante que se citen los trabajos que realmente merecen ser citados. Sin embargo, a menudo las personas investigadoras citan de forma selectiva la literatura (Duyx et al., 2017). Por ejemplo:
- Es más probable que se citen resultados estadísticamente significativos que resultados no significativos, lo cual amplifica el ya fuerte efecto del sesgo de publicación.
- Puede que no se citen críticas a su trabajo, a las herramientas que usan o al enfoque estadístico adoptado, para evitar que quienes evalúan el artículo detecten posibles debilidades.
- También influyen razones no científicas: las personas tienden a citar sus propios trabajos, incluso cuando no son los más relevantes, o los de colegas y personas cercanas, evitando citar a quienes consideran parte de un grupo externo o con quienes tienen conflictos.
Un ejemplo ilustrativo del sesgo de citación lo ofrece la literatura sobre el efecto Hawthorne. En varios estudios realizados en la planta eléctrica Hawthorne Works, se probó si diferentes condiciones de iluminación influían en la productividad. El efecto Hawthorne se refiere a un aumento general de la productividad cuando las personas saben que están siendo observadas, independientemente de las condiciones experimentales.
Esta interpretación ha sido ampliamente criticada, pero quienes investigan citan predominantemente las interpretaciones positivas e ignoran las críticas (Letrud & Hernes, 2019). Otro ejemplo famoso es una breve carta publicada en el New England Journal of Medicine que afirmaba que la adicción era rara entre pacientes tratados con narcóticos. Esta carta fue citada de forma masiva como evidencia de que los opioides eran seguros, lo que se cree que contribuyó significativamente a la actual crisis de opioides en América del Norte (Leung et al., 2017).
El sesgo de citación puede prevenirse adoptando algunas prácticas muy sencillas (aunque tristemente necesarias). Por ejemplo:
- Leer siempre los artículos que se citan (algo sorprendentemente trivial, pero fundamental, sobre todo ahora que se usan herramientas de IA que generan referencias falsas).
- Buscar de forma sistemática en la literatura, en lugar de confiar únicamente en los artículos más citados que aparecen en los primeros resultados de Google Scholar.
El sesgo de citación también puede usarse de forma activa para hacer que un artículo científico parezca más convincente para quienes lo leen. Corneille et al. (2023) mencionan este truco junto a una lista de otras estrategias que algunas personas investigadoras utilizan para que sus afirmaciones suenen más sólidas de lo que realmente son. Requiere bastante conocimiento del tema para detectar estas técnicas, que incluyen:
- Citar trabajos débiles o que ya se sabe que son erróneos,
- Hacer afirmaciones no respaldadas por evidencia,
- Generalizar más allá de lo que los datos realmente permiten,
- Seleccionar citas de forma parcial o sacarlas de contexto,
- Minimizar las limitaciones del estudio.
A medida que te desarrollas como persona investigadora, aprenderás a identificar estas técnicas. Pero para quienes tienen menos experiencia, es más difícil detectarlas. La motivación detrás de estas prácticas suele estar relacionada con el deseo de que el artículo sea aceptado en una revista científica prestigiosa, lo cual beneficia la carrera profesional.
16.2 Escepticismo Organizado

A estas alturas, está claro que existe un riesgo real de que los sesgos influyan en las afirmaciones que hacen las personas que investigan.
Siguiendo la noción de escepticismo organizado propuesta por Merton, existen diversas prácticas en la ciencia cuyo propósito es contrarrestar, en la medida de lo posible, los sesgos, permitiendo que las afirmaciones sean sometidas a un escrutinio crítico.
16.2.1 Control de errores
Cuando William Gosset (conocido como Student, del test t de Student) escribió un documento interno para la cervecería Guinness, explicaba la utilidad de usar probabilidades de error para:
“...ayudarnos a formarnos un juicio sobre el número y la naturaleza de los nuevos experimentos necesarios para confirmar o refutar diversas hipótesis que actualmente estamos considerando”.
Ya en ese primer texto, Gosset reconocía que era útil especificar de forma objetiva la tasa de error que se va a utilizar para sacar conclusiones, dado que:
“...es generalmente aceptado que dejar el rechazo de experimentos totalmente a discreción de quien los realiza es peligroso, ya que puede estar sesgado. Por ello, se ha propuesto adoptar un criterio que dependa de la probabilidad de que ocurra un error tan amplio en el número de observaciones dado.”
Una observación similar la hace el bioestadístico Irwin Bross (1971):
“Siguiendo los patrones lingüísticos que guían la formulación de convenciones, es natural usar un número redondo como el 5%. Dichos números redondos ayudan a evitar cualquier sospecha de que el valor crítico ha sido manipulado para demostrar un punto en un estudio particular.”
En resumen:
“Si se permite a las personas investigadoras establecer el nivel alfa después de mirar los datos, existe la posibilidad de que el sesgo de confirmación (o estrategias más deliberadas para evitar falsaciones)” (Uygun Tunç et al., 2023). Por ello, el uso de un nivel alfa fijo (por ejemplo, 0.05 en muchos campos) es un ejemplo claro de escepticismo organizado. Las afirmaciones deben pasar un criterio que controle las conclusiones erróneas antes de tomarse en serio.
16.2.2 Prerregistro
En el capítulo sobre los efectos del análisis de datos por parte de quien investiga, Barber (1976) presenta un ejemplo claro de una trampa relacionada con elegir la hipótesis después de observar los datos:
“Existe una trampa potencial muy seria cuando quienes investigan recopilan una gran cantidad de datos y no han planificado previamente cómo los van a analizar. [...] El problema principal aquí es que la persona decide cómo analizar los datos después de haberlos revisado visualmente o estudiado.”
Una persona investigadora puede usar un nivel alfa fijo antes de observar los datos, pero eso no es suficiente para controlar conclusiones erróneas si, posteriormente, elige el test que desea aplicar tras haber identificado patrones interesantes. La solución a este problema es el prerregistro del plan de análisis. Una vez más, el prerregistro es una forma de escepticismo organizado. No se confía ciegamente en que las personas reporten de forma imparcial sus análisis planificados. En su lugar, se les pide que usen un método de evaluación de hipótesis en el que sus pares puedan verificar si esos análisis fueron efectivamente definidos antes de tener acceso a los datos.
Es perfectamente posible que una desviación respecto al plan inicial resista el escrutinio de pares (Lakens, 2019), pero las personas investigadoras deben permitir que otras puedan evaluar de forma transparente si los análisis no fueron elegidos de manera oportunista. Cuando en un campo se espera que el personal investigador registre previamente su trabajo (como en los ensayos clínicos), el prerregistro se convierte en una implementación institucional del escepticismo organizado.
El tema del prerregistro se trata en mayor profundidad en el capítulo sobre prerregistro y transparencia.
16.2.3 Estudios de replicación independiente
Después de que se ha realizado un estudio y se ha alcanzado una conclusión, el siguiente paso crítico es que otras personas intenten replicar de forma independiente ese hallazgo. Como escribe Neher (1967):
“Quienes investigan, a menudo, no reconocen características sutiles pero cruciales de su muestra o estudio, errores mecánicos en el registro o el cálculo, y errores que surgen de su propia influencia y sesgos.”
La replicación independiente proporciona un método para explorar hasta qué punto tales características causaron un efecto. La utilidad de la replicación independiente en psicología ya había sido señalada por Mack (1951) y es igualmente importante en otros campos, como la física de partículas (Junk & Lyons, 2020). Si un hallazgo puede ser replicado de forma independiente por otras personas, es menos probable que la afirmación original esté influida por características sutiles del estudio inicial. También es menos probable que el estudio original haya sufrido problemas más graves, como fraude o una tasa inflada de errores tipo I debido a flexibilidad en el análisis de datos. Una replicación independiente exitosa no elimina completamente estas preocupaciones.
Como advierte Bakan (1967): “Si una persona investigadora está interesada en replicar el estudio de otra, debe tener en cuenta cuidadosamente la posibilidad de sugestión o su disposición a aceptar los resultados de quien realizó primero el estudio (especialmente si esa persona tiene prestigio para la segunda). También debe considerar cuidadosamente la motivación que pueda tener para demostrar que la otra está equivocada, etc.” Siempre es posible que las personas que realizan la replicación compartan los mismos sesgos sistemáticos, o simplemente observen otro error tipo I por casualidad.
Sin embargo, con cada replicación independiente exitosa, estas preocupaciones se vuelven menos probables. Una replicación independiente fallida es más difícil de interpretar. Tal vez la persona que hizo la réplica tenía la intención de arruinar el experimento porque quería obtener un resultado no significativo. O tal vez había diferencias reales entre los estudios que necesitan explorarse en investigaciones posteriores. Pero las replicaciones fallidas plantean dudas sobre la generalización de los resultados, y si varias personas no logran replicar un estudio de forma independiente, eso debe tomarse como un motivo de preocupación.
16.2.4 Revisión por pares
El ejemplo prototípico de escepticismo organizado en la ciencia es el proceso de revisión por pares. Como escribe la filósofa de la ciencia Helen Longino (1990): “He sostenido que la crítica desde puntos de vista alternativos es necesaria para la objetividad y que el sometimiento de las hipótesis y el razonamiento evidencial al escrutinio crítico es lo que limita la intrusión de preferencias subjetivas individuales en el conocimiento científico. [...] La revisión por pares se menciona a menudo como el canal estándar para este tipo de crítica”.
Recibir críticas suele ser emocionalmente difícil para muchas personas, y recibir comentarios negativos en una revisión por pares no es una experiencia agradable. Lo más sorprendente es que no se enseña a las personas jóvenes a lidiar con las críticas. Cuando otras personas enumeran todo lo que creen que está mal con un trabajo en el que alguien ha pasado meses o incluso años de su vida, simplemente esperamos que esa persona aprenda a manejar las emociones que eso genera. Es lógico sentirse mal si se recibe una crítica fuerte, especialmente si se percibe como injusta o excesiva. Con el tiempo, la mayoría —aunque no todas— las personas que investigan aprenden a desvincularse emocionalmente de la evaluación que se hace de su trabajo. Trata de no tomarte la crítica como algo personal. Después de todo, forma parte del escepticismo organizado. 
El proceso de revisión por pares funciona de la siguiente manera: cuando una persona científica ha escrito un manuscrito, lo envía a la revista científica de su elección. Las revistas tienen editores que gestionan los manuscritos enviados. Una editora o editor revisará primero si el manuscrito parece relevante para su audiencia y si tiene la calidad suficiente. Si es así, el manuscrito se envía a revisión por pares. Se contacta por correo electrónico a especialistas en el tema para ver si desean hacer la revisión. Normalmente, se intenta conseguir al menos dos personas revisoras, aunque a veces se requieren más. Las personas revisoras tienen acceso al manuscrito, pero no pueden compartirlo con otras personas, es decir, en la mayoría de los casos el proceso es confidencial. Las revisiones se hacen de forma gratuita, como parte del trabajo académico, y se concede un plazo de varias semanas para completarlas. Luego, la persona editora lee las revisiones y decide si el manuscrito será rechazado (no se publica), aceptado (se publica como está) o si requiere una revisión (las autoras deben responder a las críticas y sugerencias y reenviar el manuscrito). A veces hay varias rondas de revisión antes de que un manuscrito sea aceptado. La revisión por pares suele ser anónima. Los nombres de las personas revisoras no los conoce nadie salvo la persona editora.
Las y los investigadores dicen que es menos probable que acepten hacer una revisión si su identidad se hace pública, y afirman que firmar las revisiones dificultaría ser honestos cuando creen que un manuscrito es de baja calidad (Mulligan et al., 2013). Una encuesta más reciente encontró que el 50,8% de casi 3000 científicos cree que revelar la identidad de las personas revisoras empeoraría el proceso (Ross-Hellauer et al., 2017). Casi dos tercios creen que, si se conociera su identidad, serían menos propensos a hacer críticas duras. El anonimato tiene ventajas, pero también inconvenientes. Como escribió Longino (1996): “Su confidencialidad y privacidad lo convierten en el vehículo para afianzar visiones ya establecidas”. Es posible que las personas revisoras hagan todo lo posible para evitar que ciertos resultados —como fallos de replicación o datos que contradicen sus propias teorías— lleguen a publicarse.
Existe incluso una broma habitual entre científicos: el infame “Revisor 2”, la persona que siempre es extremadamente crítica (a veces incluso maleducada o injusta), y que recomienda rechazar manuscritos con argumentos poco sólidos. Aunque no hay evidencia empírica de que el Revisor 2 sea sistemáticamente más negativo, hay grupos como Reviewer 2 Must Be Stopped en Facebook donde se comparten experiencias negativas con la revisión por pares. Dado que la revisión por pares determina si un artículo se publica o no, hay muchas críticas y preocupaciones sobre su calidad, así como intentos de manipular el proceso (por ejemplo, alianzas entre personas que se revisan mutuamente sus artículos; véase Ferguson et al., 2014), y también intentos por mejorarlo. Algunas innovaciones recientes incluyen la revisión por pares abierta, donde los contenidos de las revisiones se hacen públicos, y la revisión firmada, donde quienes revisan adjuntan su nombre. Después de una revisión de alta calidad, un artículo debería estar bien validado (es decir, sin errores ni afirmaciones falsas), pero esto no siempre ocurre. La revisión por pares es tan buena como quienes revisan. Si las personas revisoras no están bien formadas en estadística, por ejemplo, es posible que pasen por alto errores importantes en los análisis.
Además, con la creciente carga de trabajo en el mundo académico, puede ser difícil encontrar buenas personas revisoras con tiempo para hacer una revisión minuciosa. O puede que dediquen muy poco tiempo a revisar el manuscrito. Esto está cambiando poco a poco gracias al auge de la ciencia abierta (Vazire, 2017).
Además, las personas revisoras a menudo no tienen acceso a los materiales, los datos y los scripts de análisis durante la revisión, y deben confiar en que esa parte del proceso se ha realizado correctamente, lo cual no siempre es el caso. Por estas razones, aunque la revisión por pares cumple un papel importante en la ciencia cuando se hace bien, no se puede asumir que todos los manuscritos revisados por pares estén libres de errores o afirmaciones incorrectas. La revisión por pares típicamente ocurre cuando un estudio se envía para publicación, pero también puede suceder después de que un estudio ya ha sido publicado. Esto se conoce como revisión por pares post-publicación, y ocurre, por ejemplo, en plataformas como PubPeer. Aunque no siempre les agrada a quienes investigan que se someta a su trabajo a un escrutinio adicional, esta revisión posterior ha revelado con frecuencia errores que las revisiones originales pasaron por alto, por lo que debe considerarse una herramienta valiosa que facilita el escepticismo organizado.
16.2.5 Revisión de errores
Como escribe Friedlander (1964): “Los errores en la investigación ocurren. Su prevalencia debe verse con preocupación y no aceptarse pasivamente como una consecuencia inevitable de que los humanos realicen investigaciones”. Friedlander se pone a sí mismo como ejemplo: cometió un error al calcular los coeficientes de fiabilidad en un análisis factorial, y los resultados fueron sorprendentemente bajos. Repitió el cálculo y esta vez obtuvo coeficientes mucho más altos. Como él mismo reflexiona: “Una combinación de desagrado y desconfianza hacia esos resultados, más un fuerte compromiso con un estudio casi finalizado, llevó al autor a repetir el proceso aritmético para calcular los coeficientes de fiabilidad. Mayor cuidado fue evidente en los nuevos cálculos, y como resultado, ¡todos los coeficientes superaron 0.70! Una repetición adicional no cambió los valores obtenidos. Si el autor no hubiera sentido disgusto y sorpresa ante los coeficientes bajos, es dudoso que hubiera repetido los cálculos. Se habría cometido un error tipo II.”
Rosenthal (1966) también ofrece una revisión de varios estudios donde se cometieron errores al registrar las respuestas de participantes, y esos errores iban en la dirección esperada por las hipótesis de quienes realizaban el estudio. En resumen: los errores ocurren, y son más probables cuando respaldan lo que esperábamos encontrar.nAdemás, las personas revisoras a menudo no tienen acceso a los materiales, los datos y los scripts de análisis durante la revisión, y deben confiar en que esa parte del proceso se ha realizado correctamente, lo cual no siempre es el caso. Por estas razones, aunque la revisión por pares cumple un papel importante en la ciencia cuando se hace bien, no se puede asumir que todos los manuscritos revisados por pares estén libres de errores o afirmaciones incorrectas. La revisión por pares típicamente ocurre cuando un estudio se envía para publicación, pero también puede suceder después de que un estudio ya ha sido publicado. 
Esto se conoce como revisión por pares post-publicación, y ocurre, por ejemplo, en plataformas como PubPeer. Aunque no siempre les agrada a quienes investigan que se someta a su trabajo a un escrutinio adicional, esta revisión posterior ha revelado con frecuencia errores que las revisiones originales pasaron por alto, por lo que debe considerarse una herramienta valiosa que facilita el escepticismo organizado.
En resumen: los errores ocurren, y son más probables cuando respaldan lo que esperábamos encontrar.
16.2.6 El método de las hipótesis múltiples
En muchos campos científicos no hay una tradición de especialización, y quienes investigan suelen encargarse de todas las fases del proceso: teorizar, diseñar el experimento, desarrollar instrumentos de medición, recolectar datos, analizarlos e informar resultados.
Ya en 1890, T. C. Chamberlin observaba cómo las personas científicas tienden a desarrollar afecto hacia sus propias teorías:
“En el momento en que una persona propone una explicación original para un fenómeno que parece satisfactoria, nace el afecto por su criatura intelectual; y a medida que esa explicación se convierte en una teoría definida, su afecto parental se concentra en ella, y se vuelve cada vez más querida, de modo que, aunque parezca tentativamente sostenida, no lo es de forma imparcial. En cuanto este afecto parental se apodera de la mente, se pasa rápidamente a adoptar la teoría. Se produce una selección y un ensalzamiento inconscientes de los fenómenos que armonizan con la teoría y la apoyan, y un descuido inconsciente de aquellos que no coinciden. La mente se complace en los hechos que encajan bien con la teoría y siente un desinterés natural por los que parecen obstinados. Surge una búsqueda especial —también inconsciente— de los fenómenos que la respaldan, porque la mente es guiada por sus deseos.”
Para evitar este sesgo afectivo, Chamberlin propuso el método de las hipótesis múltiples. En lugar de examinar una única hipótesis, se deben desarrollar varias hipótesis plausibles para explicar un fenómeno, sin otorgar a ninguna un estatus preferente. De esta manera, se puede examinar con más objetividad cuál de ellas está mejor sustentada por los datos:
“El esfuerzo consiste en considerar toda explicación racional posible para fenómenos nuevos, y desarrollar toda hipótesis sostenible respecto a su causa e historia. Así, quien investiga se convierte en madre o padre de una familia de hipótesis: y, por su relación parental con todas ellas, se le prohíbe encariñarse demasiado con ninguna en particular.”
16.2.6 La persona abogada del diablo
La persona abogada del diablo es quien asume el papel de escéptica y argumenta contra la posición aceptada o deseada, independientemente de si está de acuerdo con sus propios argumentos. Esta práctica tiene su origen en la Iglesia Católica, donde se utilizaba durante el proceso de canonización: el advocatus diaboli debía oponerse a la beatificación de una persona candidata, en contraposición al advocatus Dei (abogado de Dios).
La idea de asignar explícitamente ese rol dentro de un grupo parte del hecho de que muchas personas evitan criticar por miedo al rechazo interpersonal. Como ya hemos visto, este es también el motivo por el cual la revisión por pares suele ser anónima. Cuando los grupos toman decisiones, nadie es anónimo. Si se asigna formalmente a alguien el rol de abogada o abogado del diablo, al menos una persona estará a cargo de expresar críticas activamente, y estará protegida de consecuencias negativas porque es parte de su función asignada.
Otros beneficios son que esta figura fomenta la diversidad de perspectivas y contrarresta la presión por conformarse con la mayoría. Por supuesto, es importante que se escuche a esta persona y que su papel no sea meramente ceremonial —una crítica que hizo Christopher Hitchens cuando fue entrevistado por el Vaticano como abogado del diablo durante el proceso de beatificación de la Madre Teresa. No se debería decir que se usó una persona abogada del diablo solo para justificar decisiones ya tomadas. Debe haber transparencia respecto a qué críticas se plantearon y cómo se abordaron.
Otro punto importante es que esta persona debe tener conocimiento suficiente sobre buenos contraargumentos para poder desempeñar su rol con eficacia. Algunas investigaciones indican que un grupo que incluye disenso auténtico (es decir, personas que realmente tienen opiniones distintas) puede generar decisiones de mayor calidad que simplemente usar una persona en el rol formal de abogada del diablo (Nemeth et al., 2001).
16.3 Conclusión
Como ya advertía Reif (1961):
“La situación laboral de quienes hacen ciencia no es simplemente un remanso tranquilo para la actividad académica, ideal para quienes tienen un temperamento introvertido. Al igual que en el mundo empresarial o jurídico, las y los científicos trabajan en un entorno social, y están sometidos a presiones sociales y competitivas considerables.”
La ciencia es una empresa profundamente humana. Quienes investigan tienen motivaciones y deseos que pueden sesgar las afirmaciones que hacen. Sin embargo, esos mismos deseos pueden hacer que alguien persista en una hipótesis el tiempo suficiente como para realizar un descubrimiento, mientras que otras personas ya habrían abandonado. Existen prácticas a nivel individual e institucional que permiten limitar la influencia de estos sesgos. Los factores humanos son parte de la ciencia, y el sistema debe diseñarse para lograr un proceso eficiente y fiable de generación de conocimiento. Es crucial estar atentas y atentos al papel que juega el sesgo de confirmación en la ciencia, y aplicar las estrategias descritas en este capítulo para no caer en sus trampas.
Como advirtió Goethe en 1792:
“Nunca podemos ser demasiado cautos al intentar evitar sacar conclusiones apresuradas a partir de los experimentos o usarlos directamente como prueba de alguna teoría.
Pues justo en ese paso, en esa transición de la evidencia empírica al juicio, del conocimiento a la aplicación, todos los enemigos interiores del ser humano acechan: la imaginación, que lo arrastra antes de que se dé cuenta de que sus pies ya no tocan el suelo; la impaciencia, la prisa, la autosatisfacción, la rigidez, el pensamiento formalista, los prejuicios, la comodidad, la frivolidad, la inconstancia... toda esta tropa y su séquito. Allí están al acecho, y sorprenden no solo al observador activo, sino también a quien contempla y se cree a salvo de toda pasión.”
Strand (2023) escribe: “Mis colegas cercanos y yo hemos implementado un modelo de ‘copiloto’ para nuestros análisis estadísticos, en el cual compartimos datos entre nosotros para verificar y evitar errores embarazosos.” Del mismo modo, Strand (2023) afirma: “Si partimos del supuesto de que los errores ocurrirán incluso cuando las personas intenten evitarlos, debemos desarrollar métodos para revisar nuestro trabajo y encontrar esos errores.” 
Explica cómo construir el hábito de revisar el trabajo en colaboración dentro de un equipo de investigación puede actuar como una capa de protección dentro del modelo de ‘queso suizo’ de Reason sobre la causalidad de accidentes. Implementar revisiones en todos los proyectos también ayuda a reducir la idea de que el trabajo se revisa por falta de confianza, ya que se convierte en parte de la cultura del grupo. Los errores también pueden prevenirse con herramientas como los manuscritos computacionalmente reproducibles, que evitan errores de copiar y pegar (Rouder et al., 2019; Strand, 2023).

