[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mejora tus inferencias estadísticas",
    "section": "",
    "text": "1 Bienvenida\nEste es el sitio del libro Mejora tus inferencias estadísticas. Aquí puedes presentar el propósito, la audiencia y cómo está organizado.\n\n\n\n\n\n\nNota\n\n\n\nSugerencia: cada capítulo es un archivo .qmd. Edita la lista en _quarto.yml para controlar el orden.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Mejora tus inferencias estadísticas</span>"
    ]
  },
  {
    "objectID": "01-uso-de-valores-p-para-probar-una-hipotesis.html",
    "href": "01-uso-de-valores-p-para-probar-una-hipotesis.html",
    "title": "Mejora tus inferencias estadísticas",
    "section": "",
    "text": "1 Uso de los valores p para contrastar una hipótesis\n1 Uso de los valores p para contrastar una hipótesis\nLos científicos intentan responder a preguntas muy diversas recopilando datos. Una de las preguntas que interesan es si las mediciones recogidas en condiciones distintas difieren o no. La respuesta a esta pregunta es una afirmación ordinal: el investigador declara que la media de las mediciones es mayor, menor o igual al comparar condiciones.\nPor ejemplo, alguien podría interesarse por la hipótesis de que los estudiantes aprenden mejor si hacen pruebas(condición A), que requieren recuperar información previamente aprendida, en comparación con no hacer pruebas y dedicar todo el tiempo a estudiar (condición B). Tras recoger datos y observar que la media de notas es mayor en quienes hicieron pruebas, el investigador puede afirmar que el rendimiento fue mejor en A que en B. Las afirmaciones ordinales solo indican que hay una diferencia; no cuantifican el tamaño del efecto.\nPara realizar estas afirmaciones ordinales, los investigadores suelen usar un procedimiento metodológico conocido como prueba de hipótesis. Una parte de esa prueba consiste en calcular un valor p y comprobar si existe una diferencia estadísticamente significativa. “Significativo” aquí quiere decir digno de atención. La prueba de hipótesis ayuda a separar la señal (lo que merece atención) del ruido aleatorio en los datos. Es útil distinguir entre significación estadística(solo dice si el efecto observado es señal o ruido) y significación práctica (si el tamaño del efecto es lo bastante grande como para tener consecuencias relevantes). Este procedimiento sirve como salvaguarda frente al sesgo de confirmación: nuestras ganas de ver confirmadas nuestras ideas pueden llevarnos a interpretar los datos como apoyo a la hipótesis incluso cuando no lo son.\n1.1 Enfoques filosóficos de los valores p\nAntes de ver cómo se calculan, conviene revisar cómo ayudan a hacer afirmaciones ordinales al contrastar hipótesis. Un valor p es la probabilidad de observar los datos muestrales, o más extremos, asumiendo que la hipótesis nula es verdadera. Esta definición, por sí sola, no indica cómo interpretarlo. La interpretación depende de la filosofía estadística que adoptemos. En el enfoque de Fisher, el valor p es una medida continua y descriptiva de compatibilidad entre los datos observados y el modelo nulo: cuanto más pequeño es el p, mayor es la reticencia a aceptar la hipótesis nula. Este planteamiento (pruebas de significación) evalúa incompatibilidades del modelo y no especifica una hipótesis alternativa. Fisher intentó formalizarlo como inferencia fiducial, hoy minoritaria frente a teorías de decisión, verosimilitud o inferencia bayesiana. lakens.github.io\nEn el enfoque Neyman-Pearson, se especifican H₀ y H₁ y las pruebas guían la acción: si p es menor que α, se actúa “como si” H₁ fuera cierta (el tamaño exacto de p por debajo de α no cambia la decisión). Este marco no pretende cuantificar evidencia continua, sino regular decisiones sobre qué afirmaciones formular. En la práctica, muchas áreas usan un híbrido de ambos enfoques.\n1.2 Creación de un modelo nulo\nImagina dos grupos de 10 personas que puntúan la edición extendida de El Señor de los Anillos. La media de mis amistades es 8,7 y la de las amistades de mi pareja 7,7: diferencia = 1 punto. La pregunta es si esa diferencia es solo variación aleatoria o si podemos afirmar que a mi grupo le gusta más. En un contraste NHST calculamos la probabilidad de observar esa diferencia (o una mayor) asumiendo que en la población la diferencia real es 0: eso es el valor p. Si es suficientemente pequeño, emitimos la afirmación; si no, nos abstenemos. Para cuantificar qué diferencias caben esperar solo por azar, construimos un modelo nulo. Suele ser útil expresarlo en una distribución estandarizada; p. ej., la t de Student (aquí con 18 g.l.) bajo supuestos como normalidad. En la práctica los supuestos nunca se cumplen perfectamente, por eso se estudia el impacto de sus violaciones: si es pequeño, los tests siguen siendo útiles. Como las probabilidades en una distribución continua se definen sobre intervalos, el p es la probabilidad de los datos “iguales o más extremos” (la cola de la distribución). lakens.github.io\n1.3 Cálculo de un valor p\nEn una t de dos muestras, el estadístico se obtiene a partir de medias, desviaciones estándar y tamaños muestrales de cada grupo; el p es la probabilidad de observar un |t| igual o mayor al observado bajo el modelo nulo. En el ejemplo de las puntuaciones de la película, una prueba t de Student bilateral produce t = 2,5175 con p = 0,02151 (g.l. = 18).\n1.4 ¿Qué valores p puedes esperar?\nLos p-valores varían de un experimento a otro. Esto no significa que “no haya que fiarse del p”, sino que conviene entender su distribución para evitar confusiones. En el marco frecuentista, lo que importa es qué ocurre a largo plazo:\n\nCuando H₀ es verdadera y el estadístico de prueba es continuo (p. ej., una t), los p-valores siguen una distribución uniforme en (0, 1).\nSi el estadístico es discreto (p. ej., ciertos usos del ji-cuadrado), la distribución de p no es uniforme. lakens.github.io\n\n1.5 La paradoja de Lindley\nAl aumentar la potencia, la distribución de p se sesga hacia la derecha: los p muy pequeños pasan a ser más probables si hay efecto. Sin embargo, con potencias muy altas puede suceder que un p = 0,04 sea más probable bajo H₀ que bajo H₁: esto es la paradoja de Lindley. Así, un resultado “p &lt; .05” puede ser significativo en el sentido Neyman-Pearson (control de error ≤ α), pero no constituir la evidencia más favorable para H₁ desde marcos de verosimilitud o bayesianos. Una estrategia para reducir estas situaciones es bajar α en función del tamaño muestral. \nDesde una perspectiva estricta de Neyman–Pearson bastaría con decir si p &lt; α o p &gt; α, pero conviene reportar el pexacto: facilita reanálisis y permite que otros comparen ese p con el α que habrían preferido. Como las afirmaciones se hacen mediante un procedimiento con tasas máximas de error conocidas, un p no permite afirmar nada “con certeza”. Incluso con α = 0.000001, cualquier afirmación aislada puede ser errónea; por eso la replicación es importante. Esta incertidumbre a veces no se refleja en expresiones como “probar”, “demostrar” o “se sabe”. Una redacción más precisa tras un NHST significativo sería:\n“Afirmamos que hay un efecto distinto de cero, reconociendo que, si los científicos formulan afirmaciones con este procedimiento, se engañarán, a largo plazo, como mucho un α % de las veces (lo que consideramos aceptable). Supondremos, hasta que nuevos datos lo refuten, que esta afirmación es correcta.”\nTras un NHST no significativo:\n“No podemos afirmar que exista un efecto distinto de cero, reconociendo que, si se evita afirmar con este procedimiento, se errará, a largo plazo, como mucho un β % de las veces.”\nOjo: no podemos afirmar ausencia de efecto tras un resultado no significativo; conviene realizar también una prueba de equivalencia (o, si hiciste una prueba de efecto mínimo, reemplaza “distinto de cero” por ese umbral).\n1.7 Prevenir malentendidos comunes sobre los valores p\nAntes de entrar en los malentendidos, el texto introduce la idea de modelo alternativo (además del nulo). Al aumentar el tamaño muestral, el error estándar se reduce y el modelo nulo “se estrecha”; por eso una misma diferencia observada (p. ej., 0,5 puntos) resulta mucho más sorprendente con n grande que con n pequeño. Algunos programas (p. ej., G*Power) muestran en un mismo gráfico el modelo nulo (curva roja), el alternativo (azul) y el valor crítico que separa resultados significativos de no significativos. El texto usa la figura de “Omniscient Jones” (quien conoce la diferencia verdadera) para razonar sobre potencia y evidencias. Lakens+1\n1.7.1 Malentendido 1: “Un p no significativo (p &gt; .05) significa que H₀ es verdadera.”\nNo. Un p no significativo indica que no hay base suficiente (bajo ese procedimiento y α) para afirmar una diferencia; noconfirma que la diferencia sea exactamente cero. Si quieres sostener “no hay efecto relevante”, necesitas, por ejemplo, una prueba de equivalencia con márgenes previamente definidos. Lakens\n1.7.2 Malentendido 2: “Un p significativo (p &lt; .05) demuestra que H₀ es falsa.”\nTampoco. Un resultado significativo solo dice que es improbable observar datos así si H₀ fuese cierta. El marco de Neyman–Pearson guía decisiones (actuar “como si” H₁ fuera cierta cuando p &lt; α), pero no cuantifica una probabilidad de verdad de las hipótesis. Lakens\n1.7.3 Malentendido 3: “Significativo = importante.”\nNo necesariamente. “Significativo” equivale mejor a “sorprendente bajo H₀”. La relevancia práctica exige mirar tamaños del efecto, intervalos de confianza y el contexto. Un efecto diminuto puede ser significativo con n grande y, aun así, poco útil. Lakens\n1.7.4 Malentendido 4: “Si hallas un resultado significativo, la probabilidad de que sea un falso positivo es 5%.”\nEse 5% es la tasa a largo plazo cuando H₀ es verdadera (α), antes de ver los datos. Si supiéramos que H₀ es cierta, todos los significativos serían falsos positivos (100%). Tras observar p &lt; α, la pregunta “¿cuál es la probabilidad de que H₀ sea verdadera?” no la responde el p; requeriría información previa (p. ej., un marco bayesiano). Lakens\n1.7.5 Malentendido 5: “1 − p es la probabilidad de replicación.”\nNo. La probabilidad de obtener un resultado significativo en una réplica depende de la potencia (si el efecto existe), de α y de otros factores (variabilidad, diseño, ejecución…). No puede derivarse de 1 − p. La manera de saber si un efecto “replica” es replicarlo.\n1.8 Ponte a prueba\n1.8.1 Preguntas sobre qué p-valores puedes esperar\nInstrucciones. Copia este código en R y ejecútalo. El script simula 100 000 estudios, hace una t de una muestra contra 100 y dibuja el histograma de p-valores, mostrando también la potencia aproximada. Lakens\nnsims &lt;- 100000 # número de simulaciones\nm &lt;- 106 # media muestral simulada\nn &lt;- 26 # tamaño muestral\nsd &lt;- 15 # desviación típica de los datos simulados\np &lt;- numeric(nsims) # vector vacío para p-valores\nbars &lt;- 20 # número de barras del histograma\nfor (i in 1:nsims) { # para cada \"experimento\"\nx &lt;- rnorm(n = n, mean = m, sd = sd)\nz &lt;- t.test(x, mu = 100) # t de una muestra\np[i] &lt;- z$p.value # guardamos el p-valor\n}\npower &lt;- round((sum(p &lt; 0.05) / nsims), 2) # potencia\n# Gráfico\nhist(p,\nbreaks = bars, xlab = \"p-valores\", ylab = \"número de p-valores\\n\",\naxes = FALSE, main = paste(\"Distribución de p con\",\nround(power * 100, 1), \"% de potencia\"),\ncol = \"grey\", xlim = c(0, 1), ylim = c(0, nsims))\naxis(side = 1, at = seq(0, 1, 0.1), labels = seq(0, 1, 0.1))\naxis(side = 2, at = seq(0, nsims, nsims / 4),\nlabels = seq(0, nsims, nsims / 4), las = 2)\nabline(h = nsims / bars, col = \"red\", lty = 3) # línea roja = alfa del 5%\nQ1. La potencia es la probabilidad de observar un resultado significativo cuando hay efecto real. ¿Dónde la “ves” en la figura?\n\na) Contando p &gt; 0.5 y dividiéndolos entre el total.\nb) Contando los p de la primera barra (0.00–0.05) y dividiéndolos entre el total.\nc) Restando p &gt; 0.5 menos p &lt; 0.5 y dividiéndolo entre el total.\nd) Restando p &gt; 0.5 menos p &lt; 0.05 y dividiéndolo entre el total.\n\nQ2. Cambia n &lt;- 26 por n &lt;- 51 y ejecuta. ¿Qué potencia observas ahora (elige la más cercana)?\n55% · 60% · 80% · 95%\nQ3. ¿Cómo cambia la distribución de p-valores respecto a la de 50% de potencia?\n\nIgual · Mucho más empinada · Mucho más plana · Más normal (campana)\n\nQ4. Pon m &lt;- 100 (sin efecto real). Ejecuta. ¿Qué notas?\n\nIgual que con 50% de potencia · Más empinada · Básicamente plana (salvo ruido) · Normal (campana)\n\nQ5. En el caso sin efecto real, mira la primera barra (0.00–0.01 si luego aumentas barras). ¿Cómo se llama formalmente?\n\nPotencia (verdaderos positivos) · Verdaderos negativos · Error de Tipo I (falsos positivos) · Error de Tipo II (falsos negativos)\n\nAhora céntrate en p &lt; .05: cambia bars &lt;- 20 por bars &lt;- 100 y xlim = c(0, 1) por xlim = c(0, 0.05). Con m &lt;- 100 verás la uniformidad (cada barra ≈1%). Luego pon m &lt;- 107, n &lt;- 51.\nQ6. Con m &lt;- 107, la potencia ronda ~90,5% para α = .05. Si bajas α a .01, ¿qué potencia aproximada ves?\n~90% · ~75% · ~50% · ~5%\nPara examinar p entre 0.04 y 0.05, ajusta ylim = c(0, 10000). Pon m &lt;- 108, deja n &lt;- 51.\nQ7. Con potencia muy alta (~96–98%), un p = 0.045…\n\na) Es significativo y apoya fuertemente H₁.\nb) Es significativo y sin duda es Tipo I.\nc) Con alta potencia deberías usar α &lt; .05; por tanto, no es significativo.\nd) Es significativo, pero esos datos son más probables bajo H₀ que bajo H₁.\n\nQ8. Juega variando n y/o m. Para la barra 0.04–0.05 (línea roja = 1% bajo H₀), ¿cuánto más alta puede llegar a ser, en el mejor caso, bajo H₁?\nIgual · ~4× · ~10× · ~30×\nConclusión de esta parte: los p justo por debajo de .05, en el mejor caso, son como mucho un apoyo débil a H₁; conviene replicar o ser cauto al interpretarlos. Lakens\n1.8.2 Preguntas sobre malentendidos del p-valor\nResponde y contrasta con tus simulaciones o con la app enlazada en el capítulo. Lakens\nQ1. Con t independiente y n = 50 por grupo, ¿qué afirmación es correcta?\n\nLa media de diferencias es siempre 0.\nLa media de diferencias es siempre distinta de 0.\nObservar una diferencia de ±0.5 es sorprendente asumiendo H₀.\nObservar una diferencia de ±0.1 es sorprendente asumiendo H₀.\n\nQ2. ¿En qué se parecen y difieren los modelos nulos de las Figuras 1.6 y 1.7?\n\n(Pista: ambas centradas en 0; el valor crítico cambia con n.)\n\nQ3. Explora la app (muestra, efecto, α). ¿Qué visualiza la zona roja? ¿y la azul? (Tipo I y Tipo II / 1−potencia).\nQ4. Con α = .01 (mantén n = 50, diferencia = 0.5), comparado con α = .05:\n\nSolo valores menos extremos son “sorprendentes”, y el umbral pasa a ±0.53.\n… a ±0.33.\nSolo valores más extremos son “sorprendentes”, y el umbral pasa a ±0.53.\n… a ±0.33.\n\nQ5. ¿Por qué no puedes concluir que H₀ es verdadera si obtienes p &gt; α?\n\nDebes reconocer la posibilidad de Tipo II (falso negativo).\n\nQ6. ¿Por qué no puedes concluir que H₁ es verdadera si p &lt; α?\n\nDebes reconocer la posibilidad de Tipo I (falso positivo) y que p no es prob. de hipótesis.\n\nQ7. Con muestras enormes (p. ej., n = 50 000 por grupo), ¿qué efectos serán “sorprendentes”? (pistas: umbral ≈ ±0.04).\nQ8. Simula en R: rnorm(50, 0, 1) da media 0.5; t de una muestra contra 0 produce p = .03. ¿Probabilidad de “significativo por azar” si H₀ es cierta?\n3% · 5% · 95% · 100%\nQ9. ¿Cuál es la afirmación correcta sobre probabilidad de replicación?\n\n1−p · 1−p×Pr(H₀) · Potencia (si hay efecto) o α (si no lo hay) · Potencia + α\nQ10. ¿Un p = .65 implica que H₀ es verdadera?\nQ11. ¿Forma correcta de presentar un p no significativo?\n“La diferencia no fue estadísticamente distinta de 0.”\nQ12. ¿Un p &lt; .05 implica que H₀ es falsa?\nQ13. ¿Efecto significativo = efecto importante? (pista: análisis coste–beneficio, tamaños de efecto).\n\n1.8.3 Preguntas abiertas\n\n¿Qué determina la forma de la distribución de p?\n¿Cómo cambia cuando hay efecto real y aumenta n?\n¿Qué es la paradoja de Lindley?\n¿Cómo se distribuyen los p de estadísticos continuos cuando H₀ es cierta?\nDefinición correcta de p.\n¿Por qué es incorrecto pensar que un p no significativo confirma H₀?\n¿Por qué es incorrecto pensar que un p significativo refuta H₀?\n¿Por qué es incorrecto pensar que p significativo = importante?\n¿Por qué es incorrecto pensar que, si observas un resultado significativo, la prob. de Tipo I es 5%?\n¿Por qué es incorrecto pensar que 1−p es la prob. de replicación?\nDiferencias entre Fisher y Neyman–Pearson al interpretar p.\n¿Qué representa el modelo nulo (H₀) en NHST?\nSi no puedes usar NHST para concluir no hay efecto significativo/útil, ¿qué enfoques usarías (p. ej., equivalencia, región de irrelevancia, etc.)? Lakens\n\nAtribución y licencia\nTraducción no oficial de: Lakens, D. (2022). Improving Your Statistical Inferences (Sección “1.8 Test Yourself”). Recurso original con licencia CC BY-NC-SA (Atribución–No Comercial–Compartir Igual). Fuente: libro online y página del capítulo.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>01-uso-de-valores-p-para-probar-una-hipotesis.html</span>"
    ]
  },
  {
    "objectID": "02-control-de-errores.html",
    "href": "02-control-de-errores.html",
    "title": "3  Control de errores",
    "section": "",
    "text": "4 Control de errores",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Control de errores</span>"
    ]
  },
  {
    "objectID": "03-probabilidades.html",
    "href": "03-probabilidades.html",
    "title": "4  Probabilidades",
    "section": "",
    "text": "5 Probabilidades",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Probabilidades</span>"
    ]
  },
  {
    "objectID": "04-estadistica-bayesiana.html",
    "href": "04-estadistica-bayesiana.html",
    "title": "5  Estadística bayesiana",
    "section": "",
    "text": "6 Estadística bayesiana",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Estadística bayesiana</span>"
    ]
  },
  {
    "objectID": "05-formulacion-de-preguntas-estadisticas.html",
    "href": "05-formulacion-de-preguntas-estadisticas.html",
    "title": "6  Formulación de preguntas estadísticas",
    "section": "",
    "text": "7 Formulación de preguntas estadísticas",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Formulación de preguntas estadísticas</span>"
    ]
  },
  {
    "objectID": "06-tamanos-del-efecto.html",
    "href": "06-tamanos-del-efecto.html",
    "title": "7  Tamaños del efecto",
    "section": "",
    "text": "8 Tamaños del efecto",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Tamaños del efecto</span>"
    ]
  },
  {
    "objectID": "07-intervalos-de-confianza.html",
    "href": "07-intervalos-de-confianza.html",
    "title": "8  Intervalos de confianza",
    "section": "",
    "text": "9 Intervalos de confianza",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Intervalos de confianza</span>"
    ]
  },
  {
    "objectID": "08-justificacion-del-tamano-de-la-muestra.html",
    "href": "08-justificacion-del-tamano-de-la-muestra.html",
    "title": "9  Justificación del tamaño de la muestra",
    "section": "",
    "text": "10 Justificación del tamaño de la muestra",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Justificación del tamaño de la muestra</span>"
    ]
  },
  {
    "objectID": "09-pruebas-de-equivalencia-e-hipotesis-de-intervalo.html",
    "href": "09-pruebas-de-equivalencia-e-hipotesis-de-intervalo.html",
    "title": "10  Pruebas de equivalencia e hipótesis de intervalo",
    "section": "",
    "text": "11 Pruebas de equivalencia e hipótesis de intervalo",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Pruebas de equivalencia e hipótesis de intervalo</span>"
    ]
  },
  {
    "objectID": "10-analisis-secuencial.html",
    "href": "10-analisis-secuencial.html",
    "title": "11  Análisis secuencial",
    "section": "",
    "text": "12 Análisis secuencial",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Análisis secuencial</span>"
    ]
  },
  {
    "objectID": "11-metaanalisis.html",
    "href": "11-metaanalisis.html",
    "title": "12  Metanálisis",
    "section": "",
    "text": "13 Metanálisis",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Metanálisis</span>"
    ]
  },
  {
    "objectID": "12-deteccion-de-sesgos.html",
    "href": "12-deteccion-de-sesgos.html",
    "title": "13  Detección de sesgos",
    "section": "",
    "text": "14 Detección de sesgos",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Detección de sesgos</span>"
    ]
  },
  {
    "objectID": "13-prerregistro-y-transparencia.html",
    "href": "13-prerregistro-y-transparencia.html",
    "title": "14  Prerregistro y transparencia",
    "section": "",
    "text": "15 Prerregistro y transparencia",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Prerregistro y transparencia</span>"
    ]
  },
  {
    "objectID": "14-reproducibilidad-computacional.html",
    "href": "14-reproducibilidad-computacional.html",
    "title": "15  Reproducibilidad computacional",
    "section": "",
    "text": "16 Reproducibilidad computacional",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Reproducibilidad computacional</span>"
    ]
  },
  {
    "objectID": "15-integridad-de-la-investigacion.html",
    "href": "15-integridad-de-la-investigacion.html",
    "title": "16  Integridad de la investigación",
    "section": "",
    "text": "17 Integridad de la investigación",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Integridad de la investigación</span>"
    ]
  },
  {
    "objectID": "16-sesgo-de-confirmacion-y-escepticismo-organizado.html",
    "href": "16-sesgo-de-confirmacion-y-escepticismo-organizado.html",
    "title": "17  Sesgo de confirmación y escepticismo organizado",
    "section": "",
    "text": "18 Sesgo de confirmación y escepticismo organizado",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Sesgo de confirmación y escepticismo organizado</span>"
    ]
  },
  {
    "objectID": "17-estudios-de-replicacion.html",
    "href": "17-estudios-de-replicacion.html",
    "title": "18  Estudios de replicación",
    "section": "",
    "text": "19 Estudios de replicación",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Estudios de replicación</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "19  Referencias",
    "section": "",
    "text": "20 Referencias\nIncluye aquí tu bibliografía. Si usas un references.bib, cita con @clave y añade bibliography: references.bib en _quarto.yml o en los metadatos del capítulo.",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Referencias</span>"
    ]
  }
]